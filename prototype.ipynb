{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8fd0ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr #to translate speech to text\n",
    "import simpleaudio as sa\n",
    "from pydub import AudioSegment\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0e5f300",
   "metadata": {},
   "source": [
    "“The SpeechRecognition\" library acts as a wrapper for several popular speech APIs and is thus extremely flexible. One of these — the Google Web Speech API — supports a default API key that is hard-coded into the SpeechRecognition library.”\n",
    "\n",
    "\n",
    "\"Googletrans\" is a free and unlimited python library that implemented Google Translate API. This uses the Google Translate Ajax API to make calls to such methods as detect and translate. \n",
    "https://py-googletrans.readthedocs.io/en/latest/#\n",
    "https://pypi.org/project/googletrans/ \n",
    "    Note on this library usage:\n",
    "\n",
    "    *The maximum character limit on a single text is 15k.\n",
    "    *Due to limitations of the web version of google translate, this API does not guarantee that the library   would work properly at all times. (so please use this library if you don’t care about stability.)\n",
    "    *If you want to use a stable API, I highly recommend you to use Google’s official translate API.\n",
    "    *If you get HTTP 5xx error or errors like #6, it’s probably because Google has banned your client IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "56e20eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "We think you said --> good morning?\n",
      "goodMorning.wav\n"
     ]
    }
   ],
   "source": [
    "### translate using Te-Aka sound files\n",
    "\n",
    "df=pd.read_csv('metadata.csv') # read the metadata\n",
    "folder_path = os.path.abspath('TeAka_sound_files') # Set path to the audio files\n",
    "\n",
    "#get audio from the microphone\n",
    "r = sr.Recognizer()\n",
    "mic = sr.Microphone()\n",
    "\n",
    "with mic as source:\n",
    "    #r.adjust_for_ambient_noise(source)\n",
    "    print(\"Say something!\")\n",
    "    audio = r.listen(source)\n",
    "    \n",
    "# recognize speech using Google Speech Recognition\n",
    "try:\n",
    "    global m_transcipt\n",
    "    m_transcript=r.recognize_google(audio) ## to use API key-->r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")\n",
    "    print(\"We think you said --> \" + m_transcript + \"?\")\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "\n",
    "    \n",
    "# check the recorded word in the dataframe and get the audio file for that word\n",
    "if m_transcript in df.values:\n",
    "    filename=df[df['Text']==m_transcript]['Filename'].values[0]\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    print(filename)\n",
    "    wave_obj = sa.WaveObject.from_wave_file(file_path)\n",
    "    play_obj = wave_obj.play()\n",
    "    play_obj.wait_done()\n",
    "\n",
    "else:\n",
    "    print(\"Sorry! an audio file is not currently available for the requested word\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0e7d3012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "good morning\n",
      "Ata mārie\n"
     ]
    }
   ],
   "source": [
    "### translate using PyPI package for googletrans  - Only English to Māori\n",
    "\n",
    "#get audio from the microphone\n",
    "r = sr.Recognizer()\n",
    "mic = sr.Microphone()\n",
    "with mic as source:\n",
    "    #r.adjust_for_ambient_noise(source)\n",
    "    print(\"Say something!\")\n",
    "    audio = r.listen(source)\n",
    "    transcript = r.recognize_google(audio)\n",
    "    print(transcript)\n",
    "\n",
    "# using Googletrnas     \n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "translation = translator.translate(transcript, dest='mi')\n",
    "tranlated_text=translation.text\n",
    "print(tranlated_text)\n",
    "\n",
    "#get the laptop feature to voice the given text\n",
    "import subprocess\n",
    "def say(text):\n",
    "    subprocess.call(['say', text])\n",
    "say(tranlated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a7a97b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "We think you said --> what are you doing <-- in English\n",
      "Kei te aha koe\n"
     ]
    }
   ],
   "source": [
    "### detect the input language and translate it -- uses PyPI package for googletrans \n",
    "\n",
    "# using Googletrnas     \n",
    "from googletrans import Translator\n",
    "import subprocess\n",
    "\n",
    "translator = Translator()\n",
    "    \n",
    "def output_audio(transcript,dest_l):\n",
    "    translation = translator.translate(transcript, dest=dest_l)\n",
    "    tr_text=translation.text\n",
    "    print(tr_text)\n",
    "    subprocess.call(['say', tr_text]) #get the laptop feature to voice the given text\n",
    "   \n",
    "\n",
    "## get audio from the microphone\n",
    "r = sr.Recognizer()\n",
    "mic = sr.Microphone()\n",
    "with mic as source:\n",
    "    #r.adjust_for_ambient_noise(source)\n",
    "    print(\"Say something!\")\n",
    "    audio = r.listen(source)\n",
    "    transcript = r.recognize_google(audio)\n",
    "language=(translator.detect(transcript)).lang\n",
    "\n",
    "if language=='en':\n",
    "    dest_l='mi'\n",
    "    print('We think you said --> '+transcript+ ' <-- in English')\n",
    "    output_audio(transcript,dest_l)\n",
    "elif language=='mi':\n",
    "    dest_l='en'\n",
    "    print('We think you said --> '+transcript+ ' <-- in Māori')\n",
    "    output_audio(transcript,dest_l)\n",
    "else:\n",
    "    sorry_text=\"Sorry, we couldn't identify your input, please try again.\"\n",
    "    print(sorry_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20390e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (TeReo)",
   "language": "python",
   "name": "tereo-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

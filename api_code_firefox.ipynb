{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4209cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpleaudio as sa\n",
    "from pydub import AudioSegment\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import pydub\n",
    "import simpleaudio\n",
    "import librosa\n",
    "import speech_recognition as spr #to translate speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c1c059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 19:29:48.902387: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-02 19:29:48.902690: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "asr = pipeline(\"automatic-speech-recognition\", \"facebook/wav2vec2-base-960h\")\n",
    "classifier = pipeline(\"text-classification\")\n",
    "from googletrans import Translator\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c9f7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861/\n",
      "Running on public URL: https://35929.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://35929.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x2b50f4f40>,\n",
       " 'http://127.0.0.1:7861/',\n",
       " 'https://35929.gradio.app')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjuvallayil/miniforge3/envs/TeReo-gpu/lib/python3.9/site-packages/gradio/processing_utils.py:161: UserWarning: Audio data is not in 16-bit integer format.Trying to convert to 16-bit int format.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def button_update():\n",
    "    return gr.update(variant='primary')\n",
    "\n",
    "def text_to_audio(audio):\n",
    "    text = asr(audio)[\"text\"]\n",
    "    translation = translator.translate(text, dest='mi')\n",
    "    tranlated_text=translation.text\n",
    "    if 'GOD' in text:\n",
    "        concept=\"Yes!\"     \n",
    "    else:\n",
    "        concept=\"No!\"\n",
    "        \n",
    "    sentiment=classifier(text)[0][\"label\"]\n",
    "    \n",
    "    if sentiment==\"POSITIVE\" and concept==\"No!\":\n",
    "        filename = ('data/intro.wav')\n",
    "        \n",
    "    elif sentiment==\"POSITIVE\" and concept==\"Yes!\":\n",
    "        filename = ('data/learnabtgods.wav')\n",
    "    \n",
    "    else:\n",
    "        filename = ('data/KiaOra.wav')\n",
    "        \n",
    "    y, sr = librosa.load(filename)\n",
    "    return gr.update(value='To test again clear the input below (x) and Submit again..'),gr.update(visible=True),text,tranlated_text,sentiment,concept,(sr, y)\n",
    "    \n",
    "\n",
    "with gr.Blocks(css=\"\"\"\n",
    "\n",
    "body {\n",
    "    background: rgb(2,0,36);\n",
    "    background: linear-gradient(180deg, rgba(2,0,36,1) 0%, rgba(7,51,99,1) 70%, rgba(6,3,17,1) 100%); \n",
    "}\n",
    "\n",
    "\"\"\") as demo:\n",
    "    with gr.Row(visible=True):\n",
    "        gr.Image('Te Ipukarea logo.png',interactive=False,image_mode='L',label=' ').style(height=54, width=150)\n",
    "        gr.Image('AUT Maori.jpg',interactive=False,label=' ').style(height=54, width=150)\n",
    "        #gr.Image('Tui.jpg',interactive=False,label=' ').style(height=54, width=150)\n",
    "    gr.Markdown(\"\"\"\n",
    "                \n",
    "                \"\"\")\n",
    "    #gr.Markdown(\"**Record from microphone** and then **Submit** to see the output.\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            lbl1=gr.Label('Click Record from microphone below and then click Submit button to see the output..')\n",
    "            inp1 = gr.Audio(source=\"microphone\",type=\"filepath\",label='Record and Submit',visible=True)\n",
    "            btn1 = gr.Button(\"Submit\", variant='secondary')\n",
    "            gr.Image('Tui.jpg',interactive=False,label=' ').style(height=54, width=450)\n",
    "        with gr.Column(visible=False) as outs:\n",
    "            out1 = gr.Textbox(label=\"Transcripted:\")\n",
    "            out2 = gr.Textbox(label=\"Translated:\")\n",
    "            out3 = gr.Label(label=\"Sentiment Analysed:\")\n",
    "            out4 = gr.Textbox(label=\"Any domain/concept identified, eg. God?\")\n",
    "            out5 = gr.Audio()\n",
    "              \n",
    "    inp1.change(fn=button_update, inputs=None, outputs=[btn1])\n",
    "    btn1.click(fn=text_to_audio, inputs=inp1, outputs=[lbl1,outs,out1,out2,out3,out4,out5])\n",
    "    \n",
    "demo.launch(share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9296f77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (TeReo)",
   "language": "python",
   "name": "tereo-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
